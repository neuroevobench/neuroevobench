# Meta Arguments: What job? What train .py file? Base config? Where to store?
meta_job_args:
    project_name: "es_bench"
    experiment_type: "hyperparameter-search"
    base_train_fname: "train.py"  # or "mle_bash.sh" for bash script
    base_train_config: "configs/ARS/ant.yaml"
    experiment_dir: "experiments/ARS/ant"

# Parameters specific to the hyperparameter search
param_search_args:
    search_logging:
        reload_log: True
        max_objective: True
        aggregate_seeds: "mean"
        problem_type: "best"
        eval_metrics:
            - "test_perf_strat_mean"
    search_resources:
        num_search_batches: 1
        num_evals_per_batch: 100
        num_seeds_per_eval: 3
        # num_total_evals: 4
        # max_running_jobs: 8
    search_config:
        search_type: "Grid"
        search_schedule: "sync"
        search_params:
          real:
              es_params/lrate_init:
                begin: 0.001
                end: 0.04
                bins: 10
              es_params/sigma_init:
                begin: 0.01
                end: 0.1
                bins: 10

# Parameters specific to an individual job
single_job_args:
    job_name: "es_bench"
    num_gpus: 0
    num_logical_cores: 8
    log_file: "log"
    err_file: "err"
    env_name: "snippets"
    time_per_job: "00:10:00"
    # gpu_prefix: "cuda"
    queue:
        # - "rob.q"
        - "cognition-all.q"
    exclude_nodes:
      - "cognition13.ml.tu-berlin.de"
      - "cognition14.ml.tu-berlin.de"
    # partition:
        #- "ex_scioi_nodes"
        #- "ex_scioi_gpu"
    # gpu_type: "V100S"
    # memory_per_cpu: 1000