# Meta Arguments: What job? What train .py file? Base config? Where to store?
meta_job_args:
    project_name: "es_bench"
    experiment_type: "hyperparameter-search"
    base_train_fname: "train.py"  # or "mle_bash.sh" for bash script
    base_train_config: "configs/Brax/pgpe.yaml"
    experiment_dir: "experiments/Brax/PGPE"

# Parameters specific to the hyperparameter search
param_search_args:
    search_logging:
        reload_log: True
        max_objective: True
        aggregate_seeds: "mean"
        problem_type: "best"
        eval_metrics:
            - "test_perf_strat_mean"
    search_resources:
        num_search_batches: 1
        num_evals_per_batch: 5
        num_seeds_per_eval: 3
        # num_total_evals: 4
        # max_running_jobs: 8
    search_config:
        search_type: "Grid"
        search_schedule: "sync"
        search_params:
          categorical:
              problem_train_config/env_name:
                - "ant"
                - "halfcheetah"
                - "hopper"
                - "reacher"
                - "walker2d"

# Parameters specific to an individual job
single_job_args:
    job_name: "es_bench"
    num_gpus: 1
    num_logical_cores: 4
    log_file: "log"
    err_file: "err"
    env_name: "jax-cuda" #"snippets"
    time_per_job: "00:04:00"
    partition:
        - "ex_scioi_gpu"
    #     - "scioi_gpu"
    gpu_type: "v100s"
    memory_per_cpu: 5000
    # gpu_prefix: "cuda"
    # queue:
        #- "rob.q"
        # - "cognition-all.q"
    # exclude_nodes:
    #   - "cognition14.ml.tu-berlin.de"