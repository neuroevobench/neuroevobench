# Meta Arguments: What job? What train .py file? Base config? Where to store?
meta_job_args:
    project_name: "es_bench"
    experiment_type: "hyperparameter-search"
    base_train_fname: "train.py"  # or "mle_bash.sh" for bash script
    base_train_config: "configs/CMA_ES/ant.yaml"
    experiment_dir: "experiments/CMA_ES/ant"

# Parameters specific to the hyperparameter search
param_search_args:
    search_logging:
        reload_log: True
        max_objective: True
        aggregate_seeds: "mean"
        problem_type: "best"
        eval_metrics:
            - "test_perf_strat_mean"
    search_resources:
        num_search_batches: 1
        num_evals_per_batch: 100
        num_seeds_per_eval: 3
        # num_total_evals: 4
        # max_running_jobs: 8
    search_config:
        search_type: "Grid"
        search_schedule: "sync"
        search_params:
          real:
              es_params/c_m:
                begin: 0.5
                end: 1.5
                bins: 10
              es_params/sigma_init:
                begin: 0.01
                end: 0.25
                bins: 10

# Parameters specific to an individual job
single_job_args:
    job_name: "es_bench"
    num_gpus: 0
    num_logical_cores: 8
    log_file: "log"
    err_file: "err"
    env_name: "jax-cuda"
    time_per_job: "00:15:00"
    # gpu_prefix: "cuda"
    # queue:
    #     # - "rob.q"
    #     - "cognition-all.q"
    # exclude_nodes:
    #   - "cognition13.ml.tu-berlin.de"
    #   - "cognition14.ml.tu-berlin.de"
    partition: "ex_scioi_node"
        #- "ex_scioi_gpu"
    # gpu_type: "V100S"
    memory_per_cpu: 5000