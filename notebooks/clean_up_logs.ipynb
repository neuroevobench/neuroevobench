{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from mle_logging import merge_seed_logs, merge_config_logs, load_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge logs into `meta_log.hdf5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dir = \"../experiments/ARS/ant\"\n",
    "\n",
    "def get_immediate_subdirectories(a_dir):\n",
    "    return [name for name in os.listdir(a_dir)\n",
    "            if os.path.isdir(os.path.join(a_dir, name))]\n",
    "\n",
    "sub_dirs = get_immediate_subdirectories(exp_dir)\n",
    "len(sub_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists ../experiments/ARS/ant/b_1_eval_2/logs/log.hdf5\n",
      "Exists ../experiments/ARS/ant/b_1_eval_5/logs/log.hdf5\n",
      "Exists ../experiments/ARS/ant/b_1_eval_4/logs/log.hdf5\n",
      "Exists ../experiments/ARS/ant/b_1_eval_3/logs/log.hdf5\n",
      "<class 'Exception'> ../experiments/ARS/ant/b_1_eval_11/logs/log.hdf5\n",
      "Exists ../experiments/ARS/ant/b_1_eval_8/logs/log.hdf5\n",
      "Exists ../experiments/ARS/ant/b_1_eval_6/logs/log.hdf5\n",
      "Exists ../experiments/ARS/ant/b_1_eval_1/logs/log.hdf5\n",
      "Exists ../experiments/ARS/ant/b_1_eval_10/logs/log.hdf5\n",
      "Exists ../experiments/ARS/ant/b_1_eval_0/logs/log.hdf5\n",
      "Exists ../experiments/ARS/ant/b_1_eval_7/logs/log.hdf5\n",
      "Exists ../experiments/ARS/ant/b_1_eval_9/logs/log.hdf5\n"
     ]
    }
   ],
   "source": [
    "for s_dir in sub_dirs:\n",
    "    # Merge different random seeds for each config into separate .hdf5 file\n",
    "    if not os.path.exists(os.path.join(exp_dir, s_dir, \"logs/log.hdf5\")):\n",
    "        try:\n",
    "            merge_seed_logs(os.path.join(exp_dir, s_dir, \"logs/log.hdf5\"), \n",
    "                            os.path.join(exp_dir, s_dir))\n",
    "        except Exception:\n",
    "            print(Exception, os.path.join(exp_dir, s_dir, \"logs/log.hdf5\"))\n",
    "    else:\n",
    "        print(\"Exists\", os.path.join(exp_dir, s_dir, \"logs/log.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the different merged configuration .hdf5 files into single meta log\n",
    "merge_config_logs(experiment_dir=exp_dir,\n",
    "                  all_run_ids=sub_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create `hyper_log.pkl` from `meta_log.hdf5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rob/anaconda3/envs/mle-toolbox/lib/python3.9/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n"
     ]
    }
   ],
   "source": [
    "meta_log = load_log(exp_dir + \"/meta_log.hdf5\", True)\n",
    "\n",
    "metric = \"test_perf_strat_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mle_logging import load_config\n",
    "all_results = {}\n",
    "for i, e_id in enumerate(meta_log.eval_ids):\n",
    "    config = load_config(os.path.join(exp_dir, e_id + \".yaml\"), True)\n",
    "    lrate = config.train_config.es_params.lrate_init\n",
    "    sigma = config.train_config.es_params.sigma_init\n",
    "    best_perf = np.max(meta_log[e_id].stats[metric].mean)\n",
    "    all_results[i] = {\"run_id\": e_id,\n",
    "                      \"params\": {\"es_params/lrate_init\": lrate,\n",
    "                                 \"es_params/sigma_init\": sigma},\n",
    "                      metric: best_perf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mle_toolbox.utils import save_pkl_object\n",
    "save_pkl_object(all_results, os.path.join(exp_dir, \"hyper_log.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0731916ac994366e3ec5c9b7f6ac08b5be0d09771460287bbfce9f645047acc4"
  },
  "kernelspec": {
   "display_name": "Python3 (ma-vision)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
